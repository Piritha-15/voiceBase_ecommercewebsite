{"ast":null,"code":"var _jsxFileName = \"D:\\\\PROJECT1\\\\frontend\\\\src\\\\context\\\\VoiceContext.js\",\n  _s = $RefreshSig$(),\n  _s2 = $RefreshSig$();\nimport React, { createContext, useContext, useState, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst VoiceContext = /*#__PURE__*/createContext();\nexport const useVoice = () => {\n  _s();\n  const context = useContext(VoiceContext);\n  if (!context) {\n    throw new Error('useVoice must be used within a VoiceProvider');\n  }\n  return context;\n};\n_s(useVoice, \"b9L3QQ+jgeyIrH0NfHrJ8nn7VMU=\");\nexport const VoiceProvider = ({\n  children\n}) => {\n  _s2();\n  const [isListening, setIsListening] = useState(false);\n  const [recognition, setRecognition] = useState(null);\n  const [synthesis, setSynthesis] = useState(null);\n  useEffect(() => {\n    // Initialize Web Speech API\n    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      const recognitionInstance = new SpeechRecognition();\n      recognitionInstance.continuous = false;\n      recognitionInstance.interimResults = false;\n      recognitionInstance.lang = 'en-US';\n      setRecognition(recognitionInstance);\n    }\n    if ('speechSynthesis' in window) {\n      setSynthesis(window.speechSynthesis);\n    }\n  }, []);\n  const startListening = (onResult, onError) => {\n    if (!recognition) {\n      onError && onError('Speech recognition not supported');\n      return;\n    }\n    setIsListening(true);\n    recognition.onresult = event => {\n      const transcript = event.results[0][0].transcript;\n      onResult && onResult(transcript);\n      setIsListening(false);\n    };\n    recognition.onerror = event => {\n      onError && onError(event.error);\n      setIsListening(false);\n    };\n    recognition.onend = () => {\n      setIsListening(false);\n    };\n    recognition.start();\n  };\n  const stopListening = () => {\n    if (recognition) {\n      recognition.stop();\n    }\n    setIsListening(false);\n  };\n  const speak = (text, options = {}) => {\n    if (!synthesis) {\n      console.error('Speech synthesis not supported');\n      return;\n    }\n\n    // Cancel any ongoing speech\n    synthesis.cancel();\n    const utterance = new SpeechSynthesisUtterance(text);\n    utterance.rate = options.rate || 0.8; // Slower for seniors\n    utterance.pitch = options.pitch || 1;\n    utterance.volume = options.volume || 1;\n    if (options.onEnd) {\n      utterance.onend = options.onEnd;\n    }\n    synthesis.speak(utterance);\n  };\n  const stopSpeaking = () => {\n    if (synthesis) {\n      synthesis.cancel();\n    }\n  };\n  const value = {\n    isListening,\n    startListening,\n    stopListening,\n    speak,\n    stopSpeaking,\n    isSupported: !!recognition && !!synthesis\n  };\n  return /*#__PURE__*/_jsxDEV(VoiceContext.Provider, {\n    value: value,\n    children: children\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 106,\n    columnNumber: 5\n  }, this);\n};\n_s2(VoiceProvider, \"Xc9XSBoFFh+rvKmzwZzed1R+cpQ=\");\n_c = VoiceProvider;\nvar _c;\n$RefreshReg$(_c, \"VoiceProvider\");","map":{"version":3,"names":["React","createContext","useContext","useState","useEffect","jsxDEV","_jsxDEV","VoiceContext","useVoice","_s","context","Error","VoiceProvider","children","_s2","isListening","setIsListening","recognition","setRecognition","synthesis","setSynthesis","window","SpeechRecognition","webkitSpeechRecognition","recognitionInstance","continuous","interimResults","lang","speechSynthesis","startListening","onResult","onError","onresult","event","transcript","results","onerror","error","onend","start","stopListening","stop","speak","text","options","console","cancel","utterance","SpeechSynthesisUtterance","rate","pitch","volume","onEnd","stopSpeaking","value","isSupported","Provider","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["D:/PROJECT1/frontend/src/context/VoiceContext.js"],"sourcesContent":["import React, { createContext, useContext, useState, useEffect } from 'react';\r\n\r\nconst VoiceContext = createContext();\r\n\r\nexport const useVoice = () => {\r\n  const context = useContext(VoiceContext);\r\n  if (!context) {\r\n    throw new Error('useVoice must be used within a VoiceProvider');\r\n  }\r\n  return context;\r\n};\r\n\r\nexport const VoiceProvider = ({ children }) => {\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [recognition, setRecognition] = useState(null);\r\n  const [synthesis, setSynthesis] = useState(null);\r\n\r\n  useEffect(() => {\r\n    // Initialize Web Speech API\r\n    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {\r\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n      const recognitionInstance = new SpeechRecognition();\r\n      \r\n      recognitionInstance.continuous = false;\r\n      recognitionInstance.interimResults = false;\r\n      recognitionInstance.lang = 'en-US';\r\n      \r\n      setRecognition(recognitionInstance);\r\n    }\r\n\r\n    if ('speechSynthesis' in window) {\r\n      setSynthesis(window.speechSynthesis);\r\n    }\r\n  }, []);\r\n\r\n  const startListening = (onResult, onError) => {\r\n    if (!recognition) {\r\n      onError && onError('Speech recognition not supported');\r\n      return;\r\n    }\r\n\r\n    setIsListening(true);\r\n    \r\n    recognition.onresult = (event) => {\r\n      const transcript = event.results[0][0].transcript;\r\n      onResult && onResult(transcript);\r\n      setIsListening(false);\r\n    };\r\n\r\n    recognition.onerror = (event) => {\r\n      onError && onError(event.error);\r\n      setIsListening(false);\r\n    };\r\n\r\n    recognition.onend = () => {\r\n      setIsListening(false);\r\n    };\r\n\r\n    recognition.start();\r\n  };\r\n\r\n  const stopListening = () => {\r\n    if (recognition) {\r\n      recognition.stop();\r\n    }\r\n    setIsListening(false);\r\n  };\r\n\r\n  const speak = (text, options = {}) => {\r\n    if (!synthesis) {\r\n      console.error('Speech synthesis not supported');\r\n      return;\r\n    }\r\n\r\n    // Cancel any ongoing speech\r\n    synthesis.cancel();\r\n\r\n    const utterance = new SpeechSynthesisUtterance(text);\r\n    utterance.rate = options.rate || 0.8; // Slower for seniors\r\n    utterance.pitch = options.pitch || 1;\r\n    utterance.volume = options.volume || 1;\r\n    \r\n    if (options.onEnd) {\r\n      utterance.onend = options.onEnd;\r\n    }\r\n\r\n    synthesis.speak(utterance);\r\n  };\r\n\r\n  const stopSpeaking = () => {\r\n    if (synthesis) {\r\n      synthesis.cancel();\r\n    }\r\n  };\r\n\r\n  const value = {\r\n    isListening,\r\n    startListening,\r\n    stopListening,\r\n    speak,\r\n    stopSpeaking,\r\n    isSupported: !!recognition && !!synthesis\r\n  };\r\n\r\n  return (\r\n    <VoiceContext.Provider value={value}>\r\n      {children}\r\n    </VoiceContext.Provider>\r\n  );\r\n};"],"mappings":";;;AAAA,OAAOA,KAAK,IAAIC,aAAa,EAAEC,UAAU,EAAEC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE9E,MAAMC,YAAY,gBAAGN,aAAa,CAAC,CAAC;AAEpC,OAAO,MAAMO,QAAQ,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC5B,MAAMC,OAAO,GAAGR,UAAU,CAACK,YAAY,CAAC;EACxC,IAAI,CAACG,OAAO,EAAE;IACZ,MAAM,IAAIC,KAAK,CAAC,8CAA8C,CAAC;EACjE;EACA,OAAOD,OAAO;AAChB,CAAC;AAACD,EAAA,CANWD,QAAQ;AAQrB,OAAO,MAAMI,aAAa,GAAGA,CAAC;EAAEC;AAAS,CAAC,KAAK;EAAAC,GAAA;EAC7C,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACc,WAAW,EAAEC,cAAc,CAAC,GAAGf,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAM,CAACgB,SAAS,EAAEC,YAAY,CAAC,GAAGjB,QAAQ,CAAC,IAAI,CAAC;EAEhDC,SAAS,CAAC,MAAM;IACd;IACA,IAAI,yBAAyB,IAAIiB,MAAM,IAAI,mBAAmB,IAAIA,MAAM,EAAE;MACxE,MAAMC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;MACpF,MAAMC,mBAAmB,GAAG,IAAIF,iBAAiB,CAAC,CAAC;MAEnDE,mBAAmB,CAACC,UAAU,GAAG,KAAK;MACtCD,mBAAmB,CAACE,cAAc,GAAG,KAAK;MAC1CF,mBAAmB,CAACG,IAAI,GAAG,OAAO;MAElCT,cAAc,CAACM,mBAAmB,CAAC;IACrC;IAEA,IAAI,iBAAiB,IAAIH,MAAM,EAAE;MAC/BD,YAAY,CAACC,MAAM,CAACO,eAAe,CAAC;IACtC;EACF,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMC,cAAc,GAAGA,CAACC,QAAQ,EAAEC,OAAO,KAAK;IAC5C,IAAI,CAACd,WAAW,EAAE;MAChBc,OAAO,IAAIA,OAAO,CAAC,kCAAkC,CAAC;MACtD;IACF;IAEAf,cAAc,CAAC,IAAI,CAAC;IAEpBC,WAAW,CAACe,QAAQ,GAAIC,KAAK,IAAK;MAChC,MAAMC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;MACjDJ,QAAQ,IAAIA,QAAQ,CAACI,UAAU,CAAC;MAChClB,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC;IAEDC,WAAW,CAACmB,OAAO,GAAIH,KAAK,IAAK;MAC/BF,OAAO,IAAIA,OAAO,CAACE,KAAK,CAACI,KAAK,CAAC;MAC/BrB,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC;IAEDC,WAAW,CAACqB,KAAK,GAAG,MAAM;MACxBtB,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC;IAEDC,WAAW,CAACsB,KAAK,CAAC,CAAC;EACrB,CAAC;EAED,MAAMC,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIvB,WAAW,EAAE;MACfA,WAAW,CAACwB,IAAI,CAAC,CAAC;IACpB;IACAzB,cAAc,CAAC,KAAK,CAAC;EACvB,CAAC;EAED,MAAM0B,KAAK,GAAGA,CAACC,IAAI,EAAEC,OAAO,GAAG,CAAC,CAAC,KAAK;IACpC,IAAI,CAACzB,SAAS,EAAE;MACd0B,OAAO,CAACR,KAAK,CAAC,gCAAgC,CAAC;MAC/C;IACF;;IAEA;IACAlB,SAAS,CAAC2B,MAAM,CAAC,CAAC;IAElB,MAAMC,SAAS,GAAG,IAAIC,wBAAwB,CAACL,IAAI,CAAC;IACpDI,SAAS,CAACE,IAAI,GAAGL,OAAO,CAACK,IAAI,IAAI,GAAG,CAAC,CAAC;IACtCF,SAAS,CAACG,KAAK,GAAGN,OAAO,CAACM,KAAK,IAAI,CAAC;IACpCH,SAAS,CAACI,MAAM,GAAGP,OAAO,CAACO,MAAM,IAAI,CAAC;IAEtC,IAAIP,OAAO,CAACQ,KAAK,EAAE;MACjBL,SAAS,CAACT,KAAK,GAAGM,OAAO,CAACQ,KAAK;IACjC;IAEAjC,SAAS,CAACuB,KAAK,CAACK,SAAS,CAAC;EAC5B,CAAC;EAED,MAAMM,YAAY,GAAGA,CAAA,KAAM;IACzB,IAAIlC,SAAS,EAAE;MACbA,SAAS,CAAC2B,MAAM,CAAC,CAAC;IACpB;EACF,CAAC;EAED,MAAMQ,KAAK,GAAG;IACZvC,WAAW;IACXc,cAAc;IACdW,aAAa;IACbE,KAAK;IACLW,YAAY;IACZE,WAAW,EAAE,CAAC,CAACtC,WAAW,IAAI,CAAC,CAACE;EAClC,CAAC;EAED,oBACEb,OAAA,CAACC,YAAY,CAACiD,QAAQ;IAACF,KAAK,EAAEA,KAAM;IAAAzC,QAAA,EACjCA;EAAQ;IAAA4C,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACY,CAAC;AAE5B,CAAC;AAAC9C,GAAA,CAjGWF,aAAa;AAAAiD,EAAA,GAAbjD,aAAa;AAAA,IAAAiD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}